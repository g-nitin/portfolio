---
layout: page
title: Publications
---

<div class="publication-list">
  
  <div class="publication">
    <div class="publication-title">
      Towards Enhancing Road Safety in South Carolina Using Insights from Traffic and Driver-Education Data (Student Abstract)
    </div>
    <div class="publication-authors">
      N. Gupta, B. Muppasani, S. Srivastava, A. Goel, R. Hartfield, T. Buehrig, M. Reck, E. Kennedy, K. Poore, K. Tremblay, B. Srivastava, and L. Vasconcelos 
    </div>
    <div class="publication-venue">
      AAAI 2025 Student Abstract
      <a href="https://www.researchgate.net/publication/385590927_Towards_Enhancing_Road_Safety_in_South_Carolina_Using_Insights_from_Traffic_and_Driver-Education_Data" 
         class="publication-link" 
         target="_blank"
         title="View Publication">
        <i class="fas fa-external-link-alt"></i>
      </a>
    </div>
    <div class="abstract-container">
      <input type="checkbox" id="abstract1" class="abstract-toggle">
      <label for="abstract1" class="abstract-btn">Show Abstract</label>
      <div class="publication-abstract">
        In this student paper, we report on our project to enhance road safety in South Carolina (SC) by analyzing traffic data provided by the Department of Transportation and evaluating the impact of a school-level student driver education program called Alive@25. We improve the understanding of road safety using these traffic and training data to understand collision patterns and areas for improvement and assess training coverage gaps. Our approach combines geospatial analysis, economic impact assessment, temporal trend analysis, and interactive visualizations while leveraging AI techniques to clean and analyze extensive datasets. Key findings revealed higher collision rates in urban counties and rising collision rates in mostly rural areas, where Alive@25 participation is declining. These insights led to recommendations for improving road infrastructure and expanding safety training programs. This research demonstrates the potential of AI-driven insights to inform timely, cost-effective interventions and promote multi-stakeholder engagement in addressing public safety challenges while teaching students data science and AI skills and civic engagement.
      </div>
    </div>
  </div>

  <div class="publication">
    <div class="publication-title">
      Revisiting LLMs in Planning from Literature Review: a Semi-Automated Analysis Approach and Evolving Categories Representing Shifting Perspectives
    </div>
    <div class="publication-authors">
      Vishal Pallagani, Nitin Gupta, Bharath Chandra Muppasani, Biplav Srivastava
    </div>
    <div class="publication-venue">
      (Accepted; Awaiting Publication) ICAPS 2025
      <a href="https://ai4society.github.io/publications/papers_local/litevol.pdf" 
         class="publication-link" 
         target="_blank"
         title="View Publication">
        <i class="fas fa-external-link-alt"></i>
      </a>
    </div>
    <div class="abstract-container">
      <input type="checkbox" id="abstract3" class="abstract-toggle">
      <label for="abstract3" class="abstract-btn">Show Abstract</label>
      <div class="publication-abstract">
        Tracking the rapidly evolving literature at the intersection of large language models (LLMs) and planning has become increasingly complex due to significant growth in research output and shifting thematic focuses. Building on the survey by Pallagani et al.(2024), which organized 126 papers collected till November 2023 into eight categories, we present a platform that automates the extraction, categorization, and trend analysis of new papers. Our analysis reports on category drift, identifying evolving perspectives on the use of LLMs for planning. Our analysis reveals a decline in the percentage of papers for six categories, an increase in two, and the emergence of two new categories. Specifically, we contribute by (1) developing an automated system for categorizing new papers into existing or emergent categories,(2) reporting on category shifts with the addition of 47 new papers till September 2024, and (3) introducing a platform for continuous extraction, categorization, and trend tracking in LLM and planning research. This platform also features a leaderboard to encourage innovations in automated paper categorization.
      </div>
    </div>
  </div>


  <div class="publication">
    <div class="publication-title">
      Building a Plan Ontology to Represent and Exploit Planning Knowledge and Its Applications
    </div>
    <div class="publication-authors">
      B. Muppasani, N. Gupta, V. Pallagani, B. Srivastava, R. Mutharaju, M. N. Huhns, and V. Narayanan
    </div>
    <div class="publication-venue">
      CODS-COMAD 2024
      <a href="https://ai4society.github.io/publications/papers_local/CODS_24_AI_Planning_Ontology.pdf" 
         class="publication-link" 
         target="_blank"
         title="View Publication">
        <i class="fas fa-external-link-alt"></i>
      </a>
    </div>
    <div class="abstract-container">
      <input type="checkbox" id="abstract3" class="abstract-toggle">
      <label for="abstract3" class="abstract-btn">Show Abstract</label>
      <div class="publication-abstract">
        Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse. In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state. We hypothesize that given a large number of available planners and diverse planning domains, they carry essential information that can be leveraged to improve many ontology applications. We use open data on planning domains and planners to construct the most comprehensive planning ontology to date, based on supported competency questions, and demonstrate its applications in two practical use cases - planner selection and plan explanation. We have also made the ontology and associated resources available to the AI and data communities to promote further research.
      </div>
    </div>
  </div>

  <div class="publication">
    <div class="publication-title">
      SafeChat: A Framework for Building Trustworthy Collaborative Assistants and a Case Study of its Usefulness
    </div>
    <div class="publication-authors">
      Biplav Srivastava, Kausik Lakkaraju, Nitin Gupta, Vansh Nagpal, Bharath C Muppasani, Sara E Jones 
    </div>
    <div class="publication-venue">
      (Under Review) Communications of the ACM
      <a href="https://arxiv.org/abs/2504.07995" 
         class="publication-link" 
         target="_blank"
         title="View Publication">
        <i class="fas fa-external-link-alt"></i>
      </a>
    </div>
    <div class="abstract-container">
      <input type="checkbox" id="abstract1" class="abstract-toggle">
      <label for="abstract1" class="abstract-btn">Show Abstract</label>
      <div class="publication-abstract">
        Collaborative assistants, or chatbots, are data-driven decision support systems that enable natural interaction for task completion. While they can meet critical needs in modern society, concerns about their reliability and trustworthiness persist. In particular, Large Language Model (LLM)-based chatbots like ChatGPT, Gemini, and DeepSeek are becoming more accessible. However, such chatbots have limitations, including their inability to explain response generation, the risk of generating problematic content, the lack of standardized testing for reliability, and the need for deep AI expertise and extended development times. These issues make chatbots unsuitable for trust-sensitive applications like elections or healthcare. To address these concerns, we introduce SafeChat, a general architecture for building safe and trustworthy chatbots, with a focus on information retrieval use cases. Key features of SafeChat include: (a) safety, with a domain-agnostic design where responses are grounded and traceable to approved sources (provenance), and 'do-not-respond' strategies to prevent harmful answers; (b) usability, with automatic extractive summarization of long responses, traceable to their sources, and automated trust assessments to communicate expected chatbot behavior, such as sentiment; and (c) fast, scalable development, including a CSV-driven workflow, automated testing, and integration with various devices. We implemented SafeChat in an executable framework using the open-source chatbot platform Rasa. A case study demonstrates its application in building ElectionBot-SC, a chatbot designed to safely disseminate official election information. SafeChat is being used in many domains, validating its potential, and is available at: <a href="https://github.com/ai4society/trustworthy-chatbot">this https URL</a>.
      </div>
    </div>
  </div>

  <div class="publication">
    <div class="publication-title">
      On the Books in South Carolina: Mining for Jim Crow Laws
    </div>
    <div class="publication-authors">
      Kate F Boyd, Vandana Srivastava, Lance DuPre, Christopher Frear, Nitin Gupta
    </div>
    <div class="publication-venue">
      University of South Carolina
      <a href="https://scholarcommons.sc.edu/lib_facpub/63/" 
         class="publication-link" 
         target="_blank"
         title="View Publication">
        <i class="fas fa-external-link-alt"></i>
      </a>
    </div>
    <div class="abstract-container">
      <input type="checkbox" id="abstract3" class="abstract-toggle">
      <label for="abstract3" class="abstract-btn">Show Abstract</label>
      <div class="publication-abstract">
        On the Books in South Carolina: Mining for Jim Crow Laws is a collections-as-data and machine learning project by the University of South Carolina Libraries (USC), sub awarded by the University of North Carolina at Chapel Hill (UNC), and made possible by The Andrew W. Mellon Foundation, for the period of May 2022-December 2024. Following UNC’s steps from their first year of the grant, the USC project created a text corpus of South Carolina state legislature acts passed in the period from Reconstruction through the Civil Rights Movement (1868-1968). The USC team then utilized machine learning techniques to create a model classifying the laws as either Jim Crow or not.
      </div>
    </div>
  </div>

</div>
